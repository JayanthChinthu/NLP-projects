{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for downloading the data\n",
    "Num words is set to none since we are considering the all the words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=reuters.load_data(num_words=None,test_split=0.2)\n",
    "word_index=reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training samples: 8982\n",
      "No of test samples: 2246\n",
      "No of classes:46\n"
     ]
    }
   ],
   "source": [
    "print(\"No of training samples: {}\".format(len(x_train)))\n",
    "print(\"No of test samples: {}\".format(len(x_test)))\n",
    "num_class=max(y_train)+1\n",
    "print(\"No of classes:{}\".format(num_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## building a reverse dictionary to see words instead of integers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_index['in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_word={}\n",
    "for k,v in word_index.items():\n",
    "    ind_word[v]=k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "loss\n"
     ]
    }
   ],
   "source": [
    "print(ind_word[89])\n",
    "print(ind_word[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the bleached could mln at world as holding for include its i 3 start measures gnp 525 process ccb and nations bleached it 1985 do 000 april 0 a agreed bleached mln in ended cost cts must and ccb tenneco in winter 53 1 mln net diplomats and reorganization group 38 said 49 26 and plastics in this mln ccb field foreign is said bleached 10 3 group 26 38 producers had 4 is bleached mln 1 as equivalent not 145 world york and credits in 20 3 as permits in set board 1 share turnover it than growth pct dlrs\n"
     ]
    }
   ],
   "source": [
    "print(' '.join([ind_word[x] for x in x_train[4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_words = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "#onehotencoding\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='count')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='count')\n",
    "y_train = keras.utils.to_categorical(y_train, num_class)\n",
    "y_test = keras.utils.to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 10000)\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "(8982, 46)\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train[2])\n",
    "print(y_train.shape)\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(512,input_shape=(max_words, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 4s 466us/step - loss: 2.4428 - accuracy: 0.5296 - val_loss: 1.6172 - val_accuracy: 0.7030\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 3s 412us/step - loss: 1.2983 - accuracy: 0.7364 - val_loss: 1.2415 - val_accuracy: 0.7542\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 3s 406us/step - loss: 0.9339 - accuracy: 0.8075 - val_loss: 1.0919 - val_accuracy: 0.7842\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 3s 406us/step - loss: 0.7170 - accuracy: 0.8519 - val_loss: 0.9964 - val_accuracy: 0.8053\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 3s 411us/step - loss: 0.5700 - accuracy: 0.8848 - val_loss: 0.9407 - val_accuracy: 0.8209\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 3s 412us/step - loss: 0.4579 - accuracy: 0.9035 - val_loss: 0.9202 - val_accuracy: 0.8187\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 3s 412us/step - loss: 0.3771 - accuracy: 0.9205 - val_loss: 0.9064 - val_accuracy: 0.8287\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 3s 422us/step - loss: 0.3172 - accuracy: 0.9311 - val_loss: 0.9161 - val_accuracy: 0.8265\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 4s 434us/step - loss: 0.2799 - accuracy: 0.9389 - val_loss: 0.8993 - val_accuracy: 0.8231\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 3s 412us/step - loss: 0.2452 - accuracy: 0.9442 - val_loss: 0.9306 - val_accuracy: 0.8309\n",
      "2246/2246 [==============================] - 0s 198us/step\n",
      "Test_loss:0.8958225287397525\n",
      "Test_accuracy:0.8081033229827881\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=512,epochs=10,verbose=1,validation_split=0.1)\n",
    "score=model.evaluate(x_test,y_test,batch_size=512,verbose=1)\n",
    "print(\"Test_loss:{}\".format(score[0]))\n",
    "print(\"Test_accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way of preprocessing using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.69311935 0.         ... 0.         0.         0.        ]\n",
      "6.2427234182900655\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=reuters.load_data(num_words=None,test_split=0.2)\n",
    "tokenizer.fit_on_sequences(x_train)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='tfidf')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='tfidf')\n",
    "y_train = keras.utils.to_categorical(y_train, num_class)\n",
    "y_test = keras.utils.to_categorical(y_test, num_class)\n",
    "print(x_train[0])\n",
    "print(max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,input_shape=(max_words, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 4s 535us/step - loss: 2.1739 - accuracy: 0.5542 - val_loss: 1.2968 - val_accuracy: 0.7297\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 4s 462us/step - loss: 0.8766 - accuracy: 0.8248 - val_loss: 1.0307 - val_accuracy: 0.8053\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 5s 558us/step - loss: 0.5445 - accuracy: 0.8921 - val_loss: 0.9610 - val_accuracy: 0.8154\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 4s 481us/step - loss: 0.3654 - accuracy: 0.9202 - val_loss: 0.9277 - val_accuracy: 0.8320\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 4s 472us/step - loss: 0.2624 - accuracy: 0.9409 - val_loss: 0.9573 - val_accuracy: 0.8242\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 4s 527us/step - loss: 0.2169 - accuracy: 0.9500 - val_loss: 1.0199 - val_accuracy: 0.8187\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 4s 526us/step - loss: 0.1841 - accuracy: 0.9561 - val_loss: 1.0551 - val_accuracy: 0.8176\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 4s 448us/step - loss: 0.1810 - accuracy: 0.9551 - val_loss: 1.0775 - val_accuracy: 0.8154\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 4s 483us/step - loss: 0.1558 - accuracy: 0.9615 - val_loss: 1.0960 - val_accuracy: 0.8131\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 4s 492us/step - loss: 0.1577 - accuracy: 0.9603 - val_loss: 1.1201 - val_accuracy: 0.8098\n",
      "2246/2246 [==============================] - 1s 226us/step\n",
      "Test_loss:1.096245281205895\n",
      "Test_accuracy:0.8076580762863159\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=512,epochs=10,verbose=1,validation_split=0.1)\n",
    "score=model.evaluate(x_test,y_test,batch_size=512,verbose=1)\n",
    "print(\"Test_loss:{}\".format(score[0]))\n",
    "print(\"Test_accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another way of preprocessing using frequency method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01149425 0.         ... 0.         0.         0.        ]\n",
      "0.06896551724137931\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=reuters.load_data(num_words=None,test_split=0.2)\n",
    "\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='freq')\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode='freq')\n",
    "y_train = keras.utils.to_categorical(y_train, num_class)\n",
    "y_test = keras.utils.to_categorical(y_test, num_class)\n",
    "print(x_train[0])\n",
    "print(max(x_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(512,input_shape=(max_words, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(num_class))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8083 samples, validate on 899 samples\n",
      "Epoch 1/10\n",
      "8083/8083 [==============================] - 4s 464us/step - loss: 3.7121 - accuracy: 0.3652 - val_loss: 3.5276 - val_accuracy: 0.3315\n",
      "Epoch 2/10\n",
      "8083/8083 [==============================] - 5s 563us/step - loss: 3.2544 - accuracy: 0.3789 - val_loss: 2.9129 - val_accuracy: 0.3315\n",
      "Epoch 3/10\n",
      "8083/8083 [==============================] - 4s 504us/step - loss: 2.5913 - accuracy: 0.3704 - val_loss: 2.3614 - val_accuracy: 0.3315\n",
      "Epoch 4/10\n",
      "8083/8083 [==============================] - 4s 486us/step - loss: 2.2491 - accuracy: 0.3877 - val_loss: 2.2310 - val_accuracy: 0.3515\n",
      "Epoch 5/10\n",
      "8083/8083 [==============================] - 4s 468us/step - loss: 2.1274 - accuracy: 0.4530 - val_loss: 2.1195 - val_accuracy: 0.5161\n",
      "Epoch 6/10\n",
      "8083/8083 [==============================] - 3s 430us/step - loss: 2.0279 - accuracy: 0.5012 - val_loss: 2.0336 - val_accuracy: 0.5117\n",
      "Epoch 7/10\n",
      "8083/8083 [==============================] - 4s 539us/step - loss: 1.9487 - accuracy: 0.5123 - val_loss: 1.9639 - val_accuracy: 0.5039\n",
      "Epoch 8/10\n",
      "8083/8083 [==============================] - 4s 515us/step - loss: 1.8874 - accuracy: 0.5143 - val_loss: 1.9036 - val_accuracy: 0.5028\n",
      "Epoch 9/10\n",
      "8083/8083 [==============================] - 4s 475us/step - loss: 1.8312 - accuracy: 0.5171 - val_loss: 1.8497 - val_accuracy: 0.5072\n",
      "Epoch 10/10\n",
      "8083/8083 [==============================] - 3s 427us/step - loss: 1.7781 - accuracy: 0.5319 - val_loss: 1.7990 - val_accuracy: 0.5195\n",
      "2246/2246 [==============================] - 0s 213us/step\n",
      "Test_loss:1.7766749838687221\n",
      "Test_accuracy:0.5289403200149536\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(x_train,y_train,batch_size=512,epochs=10,verbose=1,validation_split=0.1)\n",
    "score=model.evaluate(x_test,y_test,batch_size=512,verbose=1)\n",
    "print(\"Test_loss:{}\".format(score[0]))\n",
    "print(\"Test_accuracy:{}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 methods which were used here are:frequency, count, tf-idf. Since the model is simple, the accuracy which was achieved using tf-idf was way too less. But, in the future, if we tweak the parameters and build a even more complex model using tf-idf, we must be able to achieve better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
